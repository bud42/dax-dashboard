DONE: keep cache of data files so we can go back through time
DONE: per project counts of each type of assessor, or can this be on per session page?
DONE: PET data
DONE: site column on processing screen
DONE: show when data was updated, later have button to update data
DONE: group by baseline/followup
DONE: session date column on processing screen
DONE: group by site instead of project, also group by assessor type instead of project,
DONE: when selecting a project, filter out columns that don't apply
DONE: graph of sessions by time, similar to jobs

TODO: eventually have dax keep track of queue status on XNAT
so we don't have to get directly from cluster

TODO: prearchive, auto-archive counts

TODO: per session page with columns for scans and assessors with filters
for project, scan type (passed), assr type (passed)

TODO: get custom statuses for orphaned jobs, more specific accre statuses

TODO: make sure all tasks appear somewhere

TODO: at bottom of jobs report, show list of warnings about jobs that have
been running for a long time, etc.

TODO: selecting rows in table affect graphs

TODO: scans/assessors: if any are questionable count usable and questionable and yellow,
if no questionable and any are usable, count the usable and green,
else if all are unusable count the unusable and red
if questcount > 0, usecount+questcount,yellow
elif usecount > 0, usecount,green
else: totcount,red

update_data.py updates data files, could write file with on dax build/update - 
since we are accessing the same data we can just save it to a file (and upload to xnat?)

# TODO: save state in tabs

# TODO: use sqlite instead of a json file

# TODO: job running should fall under NeedsQA,DoNoRun should be ignored

# TODO: display settings.xml stuff

# TODO: structural tab where you can pick rows and
# they are highlighted in boxplots: wml, ICV, etc. thickness?

# TODO: TRACULA tab

# TODO: help button on each tab that explains how it operates

# TODO: info button that explains the purpose of this report and how it works

# TODO: use a logger

# TODO: transition from data_table_experiments to data_table, requires a lot
# of keyword changes (rows as recrods to data as rows, sortable to soring,
# filterable to filtering,
# selected_row_indices to selected_rows, columms is list of dicts instead of
# just list) and probably some formatting


# _user = self.config['squeue_user']
# _file = self.datadir + '/squeue-' + self.curtime + '.txt
# cmd = 'squeue -u ' + _user + ' --format="%all" > ' + _file
# os.system(cmd)
# _cols = ['NAME', 'USER', 'TIME', 'ST', 'START_TIME', 'JOBID']
# self.squeue_df = pd.read_csv(_file, delimiter='|', usecols=_cols)
# self.squeue_df.rename(
#    columns={
#        'NAME': 'name', 'USER': 'user', 'ST': 'state',
#        'TIME': 'elapsed_time', 'START_TIME': 'start_time',
#        'JOBID': 'jobid'
#    }, inplace=True)
